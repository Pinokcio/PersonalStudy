* 메모리 계층
- 프로세스의 수행을 위해서 코드 및 데이터를 저장할 수 있는 메모리가 필수적이다.
- 일반적으로 메모리는 빠를수록 비싸고 작으며, 느릴수록 싸고 크다.
- 이러한 현실에 타협하여, 시스템은 다양한 속성을 가진 메모리를 계층적으로 사용한다.
@ Register - Cahce - Main Memeory - Mass Storage(hard disk, tape, etc...)

! 메인 메모리 부족에 대응하기 위해 운영체제는 메모리에 적재된 내용 중, 현재 중요하지 않은 것을 메인 메모리
보다 느리고 더 큰 공간을 가진 것(하드디스크 및 SSD)으로 옮김으로써 메인 메모리에 여유 공간을 확보하게 된다.

* 스왑 공간(Swap Space)
- 메모리 페이지들을 저장할 수 있는 디스크 공간
- 운영체제는 메모리 페이지를 읽어서 이 공간에 쓰고(swap out), 이 공간에서 데이터를 읽어 메모리에 탑재(swap in)
- 운영체제는 스왑 공간에 있는 모든 페이지들의 디스크 주소를 기억 및 관리해야 한다.
- 스왑 기능은 주소 변환 과정에 구현된다.
- 스왑된 페이지는 물리 메모리에 없기 때문에 MMU가 주소 변환을 수행할 수 없다.(swap in을 통해 메모리에 올라와야 함)
- PTE의 present bit을 통해 해당 페이지의 스왑 여부를 구분할 수 있다.

* 페이지 폴트
- 스왑된 페이지에 대해 주소 변환을 시도 할 경우, MMU는 페이지 폴트를 일으킨다.
- 스왑으로 인한 페이지 폴트임이 확인되면, 운영체제는 swap in 을 하여 해당 페이지를 메모리에 적재하고, 다시금 
  메모리 엑세스를 수행하도록 한다.
  
* 교체 정책
- 페이지 폴트 발생 시, 운영체제는 빈 페이지 리스트에서 페이지를 찾아서 페이지 폴트가 난 프로세스에 할당한다.
- 그러나, Memory Pressure가 높아서 빈 페이지가 없을 경우, 운영체제는 기존 페이지를 디스크에 내보내서 공간을
  확보한다.
- 내보낼 페이지를 선택하는 것은 운영체제의 교체 정책에 의해 결정된다.

* 최적 교체 정책
- 가장 나중에 접근될 페이지를 교체하는 것이 캐시 미스를 최소화할 수 있는 최적의 방법이다.
  > 이를 아는 것은 어려운 문제

* 캐시 미스의 종류
- 최초 시작(Cold-start) or 강제(Compulsory) miss : 캐시가 비어있을 때 발생하는 미스
- 용량 미스(Capacity) miss : 캐시가 꽉 찼을 때 발생하는 미스
- 충돌 (Conflict) or 세트 연관(Set-associativity) miss : 서로 다른 항목이 동일한 캐시 위치에 매핑될 때 발생하는 미스

* 정책 종류
- FIFO : 캐싱된 순서를 저장하는 큐가 존재, 먼저 들어온 큐를 먼저 교체 대상으로 삼는다.
- Random : 내보낼 페이지를 랜덤으로 선택
@ Belady's Anomaly : 우리 상식에선 캐시의 크기가 커질수록 용량 미스가 적어지므로 캐시 미스가 줄어들 것이라고
  생각할 수 있다. 그러나, 이는 오직 캐시 정책이 스택 특성을 보일때만 옳다. FIFO와 Randmo은 이러한 특성을
  보이지 않는다.
  
* 과거 정보 사용
- 보다 나은 교체 정책을 위해, 스케줄링과 같이 과거 이력을 활용해본다.
- 지역성에 관련된 두 종류의 과거 정보를 활용한다.
  > LRU(최근성 / 가장 최근에 접근한 페이지는 다시 접근할 가능성이 높다.)
  > LFU(빈도수 / 자주 접근한 페이지는 분명 가치가 있었을 것이기 때문에 교체하면 안될 것이다.)
  
* LRU 정책 근사하기
- LRU를 보다 효율적으로 구현하기 위해, 정교하게 가장 오래전 참조된 페이지를 교체 대상으로 삼기보다, 아직까지
  참조되지 않은 페이지 중 하나를 교체 대상으로 삼는 방식으로 근사한다.
- 이를 위해선 참조된 페이지와 그렇지 않은 페이지를 구분할 수 있어야 한다.
  > 하드웨어는 각 페이지 별로 사용여부를 나타내는 use bit을 관리한다
  > use bit은 0으로 초기화되어 있으며, 페이지 접근 시 1로 설정된다.
  > use bit은 오직 운영체제에 의해서만 0으로 다시 초기화된다.
- use bit을 이용해 LRU에 근사한 것으로 시계 알고리즘이 있다.

* 시계 알고리즘
- 모든 페이지를 환형(Circular)리스트로 관리
- 시계 바늘이 계속해서 각 페이지의 use bit을 검사한다.
  > use bit이 1일 경우, 최근에 접근된 페이지이기 때문에 교체 대상이 아니며, use bit을 0으로 초기화하고
    다음 페이지로넘어간다.
  > use bit이 0일 경우 교체 대상이 된다.
  > 이러한 순차 검색 방식은 코너 케이스가 예상되기 때문에 이를 회피하기 위해 시계 바늘을 랜덤으로 돌릴
    수 있을 것이다.

* 갱신된 페이지 (Dirty Pages) 고려
- 시계 알고리즘의 성능을 추가적으로 개선할 수 있다.
- 똑같이 사용된 페이지들이라고 하더라도 더러운(수정된 적이 있는) 페이지는 깨끗한 페이지보다 디스크에 내보내는 
  것이 오래 걸릴 것이다.
- 이를 지원하기 위해 하드웨어는 dirty bit을 포함하기도 한다.
- 이제 시계 알고리즘은 use bit이 0이면서 dirty bit이 0인 페이지를 교체 대상으로 찾게 된다.
- 만약 그러한 페이지가 없을 경우, dirty bit은 1이지만, use bit이 0인 페이지를 교체 대상으로 찾는다.

* 페이지 선택 정책
- 운영체제는 언제 디스크에 있는 페이지를 메모리로 불러들일지 결정해야만 한다.
- 요구 페이징(Demand Paging) : 상당수 운영체제는 해당 페이지에 대한 참조 요청이 있을 때 즉시 페이지를 
  디스크로부터 불러오게 된다. 즉, 디스크를 미리 물리 페이지에 로드하지 않는다. 이는 전체 페이지를 
  디스크에서 읽어오는 것보다 반응성이 좋다.
- 선반입 : 근 시일내에 접근할 페이지를 예상하여 미리 반입한다. 지역성에 근거하여 N번째 페이지가 메모리에 
  로드될 때, N+1번째 페이지도 같이 로드하도록 한다.

* 클러스터링, 그룹핑
- 디스크는 잘게 쪼개진 쓰기보다 하나의 큰 쓰기 요청에 특화되어 있다.
- 따라서, 다수의 교체 요청을 모아서 한 번에 처리하도록 한다.

* 쓰레싱
- 프로세스의 요구 메모리가 너무 많아져 사용 물리 메모리 크기를 넘어설 때 운영체제는 끊임없이 페이징을
  할 수 밖에 없으며 이러한 상황을 쓰래싱이라고 한다.
- 운영체제는 이러한 상황에 빠질 경우, 많은 프로세스를 엉성하게 실행하는 대신 소수의 프로세스를 제대로 
  실행하는게 낫다고 생각하여 일부 프로세스의 실행을 중지하기도 한다.
  
* Null 포인터 역참지 방조
- 많은 경우 Null(0) 포인터는 초기화된 상태를 나타낸다. 
- 즉, 포인터는 어떠한 오브젝트도 가리키지 않는다.
- 이때 포인터 역 참조는 프로그램의 버그일 것이다.
- 이러한 Null 포인터 참조를 쉽게 검출할 수 있도록, 프로세스의 첫 번째 PTE, 즉 가상주소 0은 invali로 
    설정하여 세그먼트 폴트가 발생하도록 유도한다.
     
* Demand-zero page
- mmap이나 brk등으로 새로운 메모리가 할당될 때, 해당 메모리는 0으로 초기화되어야만 한다.
- 그러나, 매번 메모리를 0으로 초기화하는 것은 오버헤드가 클 수 있기 때문에, 운영체제는 하나의 zero page
  를 사용할 수 있다.
  > zero page는 읽기전용으로 설정된 페이지들에 공통으로 할당되며, 임의의 쓰기가 발생하여 fault가 발생하면
  다른 물리 페이지를 할당

* Copy-on-Write(CoW)
- CoW는 여러 가상 페이지가 동일한 내용을 가지고 있을 때, 동일한 내용을 가지고 있는 물리 페이지를 여러 개
  만드는 대신 하나의 물리 페이지를 공유하도록 한다.
  > 중복된 물리 페이지에 의한 메모리 오버헤드 감소
  > 중복된 물리 페이지 생성에 소모되는 시간 감소
- 공유된 페이지는 읽기 전용으로 설정된 후, 쓰기 연산이 발생하면 on-demand로 복사본을 생성하게 된다.
- CoW는 fork의 성능 향상 및 zero page 공유 등에 사용된다.
